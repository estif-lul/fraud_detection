{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c99d9f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f1ec3f",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Loads the fraud and credit card datasets from CSV files. Handles missing file errors gracefully by printing an error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85000b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "try:\n",
    "    fraud_df = pd.read_csv('../data/processed/cleaned_fraud_data.csv')\n",
    "    credit_df = pd.read_csv('../data/processed/cleaned_credit_data.csv')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Please check the file paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f6349d",
   "metadata": {},
   "source": [
    "## Fraud Data: Train/Test Split, SMOTE, and Scaling\n",
    "Prepares the fraud dataset for modeling: drops the target column, one-hot encodes categorical variables, splits the data, balances classes using SMOTE, and scales the 'Amount' feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b8ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare fraud detection data\n",
    "# Assuming 'class' is the target variable in fraud_df\n",
    "Xf = fraud_df.drop(columns=['class'])\n",
    "yf = fraud_df['class']\n",
    "\n",
    "# One-hot encode before sampling\n",
    "Xf = pd.get_dummies(Xf)\n",
    "\n",
    "Xf_train, Xf_test, yf_train, yf_test = train_test_split(Xf, yf, stratify=yf, test_size=0.3, random_state=42)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "Xf_train_resampled, yf_train_resampled = smote.fit_resample(Xf_train, yf_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Only scale 'Amount'\n",
    "Xf_train_resampled['Amount'] = scaler.fit_transform(Xf_train_resampled[['Amount']])\n",
    "Xf_test['Amount'] = scaler.transform(Xf_test[['Amount']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ae8587",
   "metadata": {},
   "source": [
    "## Credit Card Data: Train/Test Split, SMOTE, and Scaling\n",
    "Prepares the credit card dataset for modeling: drops the target column, splits the data, balances classes using SMOTE, and scales the 'Amount' feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf58e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare credit card fraud data\n",
    "# Assuming 'Class' is the target variable in credit_df\n",
    "Xc = credit_df.drop(columns='Class')\n",
    "yc = credit_df['Class']\n",
    "\n",
    "\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc, yc, stratify=yc, test_size=0.3, random_state=42)\n",
    "\n",
    "# smote for credit card fraud data\n",
    "smote = SMOTE(random_state=42)\n",
    "Xc_train_resampled, yc_train_resampled = smote.fit_resample(Xc_train, yc_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Only scale 'Amount'\n",
    "Xc_train_resampled['Amount'] = scaler.fit_transform(Xc_train_resampled[['Amount']])\n",
    "Xc_test['Amount'] = scaler.transform(Xc_test[['Amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f65cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train Logistic Regression models\n",
    "# Using max_iter=1000 to ensure convergence\n",
    "log_fraud = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_fraud.fit(Xf_train_resampled, yf_train_resampled)\n",
    "\n",
    "log_credit = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_credit.fit(Xc_train_resampled, yc_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082ac07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Train XGBoost models with appropriate scale_pos_weight\n",
    "# Adjust scale_pos_weight based on the class imbalance\n",
    "# For fraud detection, we assume a lower imbalance, hence a lower scale_pos_weight\n",
    "\n",
    "xgb_fraud = XGBClassifier(scale_pos_weight=10, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_fraud.fit(Xf_train_resampled, yf_train_resampled)\n",
    "\n",
    "# For credit card fraud, we assume a higer imbalance, hence a higer scale_pos_weight\n",
    "xgb_credit = XGBClassifier(scale_pos_weight=50, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_credit.fit(Xc_train_resampled, yc_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db78fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc, f1_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates a classification model's performance on test data.\n",
    "\n",
    "    Prints the confusion matrix, classification report, F1 score, and area under the precision-recall curve (AUC-PR).\n",
    "    \n",
    "    Parameters:\n",
    "        model: Trained classification model with predict and predict_proba methods.\n",
    "        X_test: Test features.\n",
    "        y_test: True labels for test data.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "    auc_pr = auc(recall, precision)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC-PR: {auc_pr:.4f}\")\n",
    "\n",
    "# Evaluate models on test data\n",
    "evaluate_model(log_fraud, Xf_test, yf_test)\n",
    "evaluate_model(xgb_fraud, Xf_test, yf_test)\n",
    "\n",
    "evaluate_model(log_credit, Xc_test, yc_test)\n",
    "evaluate_model(xgb_credit, Xc_test, yc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f33787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c19e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(xgb_fraud)\n",
    "shap_values = explainer.shap_values(Xf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9414bf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, Xf_test, plot_type=\"bar\", max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66125ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0], Xf_test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc44bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.decision_plot(explainer.expected_value, shap_values[0], Xf_test.iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
